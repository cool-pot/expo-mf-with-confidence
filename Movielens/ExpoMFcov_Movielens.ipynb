{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu May  4 15:37:09 2017\n",
    "\n",
    "@author: zhouyi\n",
    "\"\"\"\n",
    "import glob\n",
    "import os\n",
    "# if you are using OPENBLAS, you might want to turn this option on. Otherwise, joblib might get stuck\n",
    "# os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "\n",
    "import expomf_cov\n",
    "from expomf_cov import get_mu,inv_logit\n",
    "\n",
    "\n",
    "DATA_ROOT = '/Users/zhouyi/Documents/GraduatePJ/ml-1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_uid = list()\n",
    "with open(os.path.join(DATA_ROOT, 'unique_uid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_uid.append(line.strip())\n",
    "    \n",
    "unique_sid = list()\n",
    "with open(os.path.join(DATA_ROOT, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_songs = len(unique_sid)\n",
    "n_users = len(unique_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 2019)\n",
      "(636096,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(csv_file, shape=(n_users, n_songs)):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    rows, cols = np.array(tp['uid'], dtype=np.int32), np.array(tp['sid'], dtype=np.int32)\n",
    "    count = tp['rating']\n",
    "    return scipy.sparse.csr_matrix((count,(rows, cols)), dtype=np.int16, shape=shape), rows, cols\n",
    "\n",
    "train_data, rows, cols = load_data(os.path.join(DATA_ROOT, 'train.num.csv'))\n",
    "# binarize the data\n",
    "train_data.data = np.ones_like(train_data.data)\n",
    "\n",
    "print train_data.shape\n",
    "print train_data.data.shape\n",
    "\n",
    "vad_data, rows_vad, cols_vad = load_data(os.path.join(DATA_ROOT, 'vad.num.csv'))\n",
    "# binarize the data\n",
    "vad_data.data = np.ones_like(vad_data.data)\n",
    "\n",
    "test_data, rows_test, cols_test = load_data(os.path.join(DATA_ROOT, 'test.num.csv'))\n",
    "# binarize the data\n",
    "test_data.data = np.ones_like(test_data.data)\n",
    "\n",
    "pi = np.loadtxt(os.path.join(DATA_ROOT, 'genre_movies_vector'), dtype='float32',skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sanity check to make sure all the venues has its corresponding feature    \n",
    "for i, s in enumerate(unique_sid):\n",
    "    assert s == \"%d\" % pi[i, 0]\n",
    "    #check if there is zero factor, it should be sumed to 1\n",
    "    assert sum(pi[i, 1:]) > 0.9\n",
    "\n",
    "pi = pi[:, 1:]             \n",
    "noise=np.random.rand(2019,18)/40\n",
    "pi+=noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0\n",
      "\tUpdating user factors: time=2.83\n",
      "\tUpdating item factors: time=2.25\n",
      "\tUpdating user exposure factors...\n",
      "\t\tEpoch #0: initial validation loss = 1776.250\n",
      "\t\tEpoch #0: validation loss = 1670.484\n",
      "\t\tEpoch #1: initial validation loss = 1700.696\n",
      "\t\tEpoch #1: validation loss = 1702.813\n",
      "\t\tEpoch #2: initial validation loss = 1608.493\n",
      "\t\tEpoch #2: validation loss = 1603.740\n",
      "\t\tEpoch #3: initial validation loss = 1776.467\n",
      "\t\tEpoch #3: validation loss = 1775.429\n",
      "\t\tEpoch #4: initial validation loss = 2020.725\n",
      "\t\tEpoch #4: validation loss = 2012.521\n",
      "\t\tEpoch #5: initial validation loss = 1691.177\n",
      "\t\tEpoch #5: validation loss = 1695.436\n",
      "\t\tEpoch #6: initial validation loss = 1755.226\n",
      "\t\tEpoch #6: validation loss = 1759.432\n",
      "\t\tEpoch #7: initial validation loss = 1780.237\n",
      "\t\tEpoch #7: validation loss = 1780.844\n",
      "\t\tEpoch #8: initial validation loss = 1641.027\n",
      "\t\tEpoch #8: validation loss = 1641.652\n",
      "\t\tEpoch #9: initial validation loss = 1760.506\n",
      "\t\tEpoch #9: validation loss = 1761.887\n",
      "\tUpdating user exposure factors: time=8.68\n",
      "\tValidation NDCG@k: 0.02807\n",
      "ITERATION #1\n",
      "\tUpdating user factors: time=1.29\n",
      "\tUpdating item factors: time=1.29\n",
      "\tUpdating user exposure factors...\n",
      "\t\tEpoch #0: initial validation loss = 2112.584\n",
      "\t\tEpoch #0: validation loss = 2028.711\n",
      "\t\tEpoch #1: initial validation loss = 2068.733\n",
      "\t\tEpoch #1: validation loss = 2069.760\n",
      "\t\tEpoch #2: initial validation loss = 2009.815\n",
      "\t\tEpoch #2: validation loss = 2014.196\n",
      "\t\tEpoch #3: initial validation loss = 2119.732\n",
      "\t\tEpoch #3: validation loss = 2121.270\n",
      "\t\tEpoch #4: initial validation loss = 2009.762\n",
      "\t\tEpoch #4: validation loss = 2012.268\n",
      "\t\tEpoch #5: initial validation loss = 2131.613\n",
      "\t\tEpoch #5: validation loss = 2132.521\n",
      "\t\tEpoch #6: initial validation loss = 2089.435\n",
      "\t\tEpoch #6: validation loss = 2091.958\n",
      "\t\tEpoch #7: initial validation loss = 2119.091\n",
      "\t\tEpoch #7: validation loss = 2120.785\n",
      "\t\tEpoch #8: initial validation loss = 1992.148\n",
      "\t\tEpoch #8: validation loss = 1992.826\n",
      "\t\tEpoch #9: initial validation loss = 2018.764\n",
      "\t\tEpoch #9: validation loss = 2018.885\n",
      "\tUpdating user exposure factors: time=6.08\n",
      "\tValidation NDCG@k: 0.05092\n",
      "ITERATION #2\n",
      "\tUpdating user factors: time=1.40\n",
      "\tUpdating item factors: time=1.30\n",
      "\tUpdating user exposure factors...\n",
      "\t\tEpoch #0: initial validation loss = 2271.508\n",
      "\t\tEpoch #0: validation loss = 2197.224\n",
      "\t\tEpoch #1: initial validation loss = 2179.942\n",
      "\t\tEpoch #1: validation loss = 2182.316\n",
      "\t\tEpoch #2: initial validation loss = 2233.562\n",
      "\t\tEpoch #2: validation loss = 2240.623\n",
      "\t\tEpoch #3: initial validation loss = 2179.712\n",
      "\t\tEpoch #3: validation loss = 2179.405\n",
      "\t\tEpoch #4: initial validation loss = 2193.677\n",
      "\t\tEpoch #4: validation loss = 2195.748\n",
      "\t\tEpoch #5: initial validation loss = 2221.306\n",
      "\t\tEpoch #5: validation loss = 2222.509\n",
      "\t\tEpoch #6: initial validation loss = 2181.946\n",
      "\t\tEpoch #6: validation loss = 2183.240\n",
      "\t\tEpoch #7: initial validation loss = 2231.435\n",
      "\t\tEpoch #7: validation loss = 2228.946\n",
      "\t\tEpoch #8: initial validation loss = 2140.482\n",
      "\t\tEpoch #8: validation loss = 2143.560\n",
      "\t\tEpoch #9: initial validation loss = 2217.267\n",
      "\t\tEpoch #9: validation loss = 2217.178\n",
      "\tUpdating user exposure factors: time=6.21\n",
      "\tValidation NDCG@k: 0.05431\n",
      "ITERATION #3\n",
      "\tUpdating user factors: time=1.41\n",
      "\tUpdating item factors: time=1.39\n",
      "\tUpdating user exposure factors...\n",
      "\t\tEpoch #0: initial validation loss = 2328.695\n",
      "\t\tEpoch #0: validation loss = 2291.211\n",
      "\t\tEpoch #1: initial validation loss = 2266.593\n",
      "\t\tEpoch #1: validation loss = 2266.022\n",
      "\t\tEpoch #2: initial validation loss = 2271.270\n",
      "\t\tEpoch #2: validation loss = 2272.607\n",
      "\t\tEpoch #3: initial validation loss = 2281.650\n",
      "\t\tEpoch #3: validation loss = 2282.113\n",
      "\t\tEpoch #4: initial validation loss = 2239.756\n",
      "\t\tEpoch #4: validation loss = 2240.448\n",
      "\t\tEpoch #5: initial validation loss = 2256.881\n",
      "\t\tEpoch #5: validation loss = 2257.890\n",
      "\t\tEpoch #6: initial validation loss = 2264.661\n",
      "\t\tEpoch #6: validation loss = 2265.411\n",
      "\t\tEpoch #7: initial validation loss = 2311.713\n",
      "\t\tEpoch #7: validation loss = 2311.363\n",
      "\t\tEpoch #8: initial validation loss = 2280.070\n",
      "\t\tEpoch #8: validation loss = 2281.321\n",
      "\t\tEpoch #9: initial validation loss = 2277.970\n",
      "\t\tEpoch #9: validation loss = 2278.269\n",
      "\tUpdating user exposure factors: time=7.35\n",
      "\tValidation NDCG@k: 0.05426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExpoMF(batch_sgd=10, batch_size=1000, early_stopping=True, init_std=0.01,\n",
       "    max_epoch=10, max_iter=15, n_components=18, n_jobs=20,\n",
       "    random_state=98765,\n",
       "    save_dir='Movielens_params_K18_lam1E-05_initmu1E-01_maxepoch10',\n",
       "    save_params=True, verbose=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 18\n",
    "max_iter = 15\n",
    "n_jobs = 20\n",
    "lam = 1e-5\n",
    "# here we use the best performing init_mu from per-item \\mu_i experiment\n",
    "init_mu = 0.1\n",
    "max_epoch = 10\n",
    "\n",
    "save_dir=\"Movielens_params_K%d_lam%1.0E_initmu%1.0E_maxepoch%d\" % (n_components, lam, init_mu, max_epoch)\n",
    "\n",
    "\n",
    "coder = expomf_cov.ExpoMF(n_components=n_components, max_iter=max_iter, batch_size=1000, \n",
    "                          batch_sgd=10, max_epoch=max_epoch, init_std=0.01,\n",
    "                          n_jobs=n_jobs, random_state=98765, save_params=True, save_dir=save_dir, \n",
    "                          early_stopping=True, verbose=True, \n",
    "                          lam_y=1., lam_theta=lam, lam_beta=lam, lam_nu=lam, init_mu=init_mu, learning_rate=.5)\n",
    "\n",
    "coder.fit(train_data, pi, vad_data=vad_data,k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
